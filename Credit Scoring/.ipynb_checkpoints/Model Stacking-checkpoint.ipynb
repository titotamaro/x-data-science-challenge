{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.filterwarnings('ignore') # Just ignore user warning\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "dataset = pd.read_csv('datatrain_complete.csv')\n",
    "X = dataset.drop('flag_kredit_macet', axis=1)\n",
    "y = dataset['flag_kredit_macet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, VotingClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "LR1 = LogisticRegression(C=100, class_weight='balanced', max_iter=10, penalty='l2', random_state=1, n_jobs=-1)\n",
    "LR2 = LogisticRegression(class_weight='balanced', max_iter=10, penalty='l1', random_state=1, n_jobs=-1)\n",
    "\n",
    "KNN1 = KNeighborsClassifier(n_neighbors=5, weights='distance', p=1)\n",
    "\n",
    "KNN2 = KNeighborsClassifier(n_neighbors=30, weights='distance', p=1)\n",
    "\n",
    "RF1 = RandomForestClassifier(class_weight='balanced', criterion='entropy', max_depth=5, max_features='sqrt',\n",
    "                             min_samples_leaf=1, min_samples_split=8, n_estimators=100, n_jobs=-1, random_state=1)\n",
    "\n",
    "RF2 = RandomForestClassifier(class_weight='balanced',criterion='gini', max_depth=5, max_features='sqrt',\n",
    "                             min_samples_leaf=1, min_samples_split=2, n_estimators=10, n_jobs=-1, random_state=1)\n",
    "\n",
    "LGBM = LGBMClassifier(boosting_type='gbdt', class_weight='balanced', learning_rate=0.05,\n",
    "                      n_estimators=100, n_jobs=-1, num_leaves=32, random_state=1)\n",
    "\n",
    "LR_meta = LogisticRegression(max_iter=10, random_state=1, n_jobs=-1, class_weight='balanced')\n",
    "RF_meta = RandomForestClassifier()\n",
    "\n",
    "GBM = GradientBoostingClassifier(max_depth=5, random_state=1)\n",
    "\n",
    "XGB = XGBClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "BA = BaggingClassifier(n_estimators=100, bootstrap_features=True, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = StackingClassifier(classifiers=[LR1, KNN2, RF1, GBM, LGBM, XGB, BA], use_probas=True, meta_classifier=LR_meta)\n",
    "VC = VotingClassifier(estimators=[('LR',LR1), ('KNN',KNN2), ('RF',RF1), ('GBM',GBM), ('LGBM',LGBM), ('XGB',XGB), ('BA',BA)],\n",
    "                      voting='soft', n_jobs=-1)\n",
    "VC2 = VotingClassifier(estimators=[('LR1',LR1), ('LR2',LR2), ('KNN1',KNN1), ('KNN2',KNN2), ('RF1',RF1), ('RF2',RF2),\n",
    "                                   ('GBM',GBM), ('LGBM',LGBM), ('XGB',XGB), ('BA',BA)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
